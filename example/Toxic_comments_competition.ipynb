{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from textDataset import *\n",
    "\n",
    "from models import BoWClassifier, Tfid\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from trainner import TrainnerNLP\n",
    "\n",
    "from gensim.models import word2vec\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import neighbors\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.models import HoverTool, BoxSelectTool\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "sns.set_context(\"notebook\", font_scale=1.5,\n",
    "                rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_count = 2*multiprocessing.cpu_count()-1\n",
    "print('Number of CPUs: {}'.format(cpu_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path2data = '../data/sentiment_analysis/'\n",
    "\n",
    "text = {\n",
    "        'train': TextDataset(path2data + 'train/', extension='.tsv', sep='\\t', is_train = True),\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#col = 'headline_text'\n",
    "#col = 'comment_text'\n",
    "col = 'Phrase'\n",
    "text['train'].process_data(col = col, remove_stopw = True, remove_tags=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['train'].data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = { 'train': text['train'].data[col + '_data'].values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = sentences['train']\n",
    "#classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "classes = ['Sentiment']\n",
    "y = np.concatenate([np.array(i) for i in text['train'].data[classes].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_count=pd.value_counts(y, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Index = np.arange(1,len(class_count)+1)\n",
    "classes = ['negative','neutral','somewhat negative','somewhat positive','positive']\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.bar(Index,class_count,color = 'blue')\n",
    "plt.xticks(Index,classes,rotation=45)\n",
    "plt.ylabel('count')\n",
    "plt.bar(Index, class_count)\n",
    "for a,b in zip(Index, class_count):\n",
    "    plt.text(a, b, str(b) ,color='green', fontweight='bold')\n",
    "    \n",
    "fig.savefig('../figures/count_words.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data in training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 50   # Minimum word count                        \n",
    "num_workers = cpu_count  # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "\n",
    "\n",
    "W2Vmodel = word2vec.Word2Vec(X_train, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "'''\n",
    "W2Vmodel.build_vocab([x for x in tqdm(X_train)])\n",
    "W2Vmodel.train([x for x in tqdm(X_train)], \\\n",
    "            total_examples=model.corpus_count, epochs=model.epochs)\n",
    "'''\n",
    "'''\n",
    "# train model\n",
    "W2Vmodel = word2vec.Word2Vec(X_train, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "W2Vmodel.init_sims(replace=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://ahmedbesbes.com/sentiment-analysis-on-twitter-using-word2vec-and-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, model, num_features):\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,), dtype=\"float32\")\n",
    "    nwords = 0\n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1\n",
    "            featureVec = np.add(featureVec, model[word])\n",
    "    # Divide the result by the number of words to get the average\n",
    "    if nwords == 0:\n",
    "        nwords = 1\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    # Given a set of reviews (each one a list of words), calculate \n",
    "    # the average feature vector for each one and return a 2D numpy array \n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    reviewFeatureVecs = np.zeros((len(reviews), num_features), dtype=\"float32\")\n",
    "    counter = 0\n",
    "    # Loop through the reviews\n",
    "    for review in reviews:\n",
    "        # Call the function (defined above) that makes average feature vectors\n",
    "        reviewFeatureVecs[counter] = makeFeatureVec(review, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return reviewFeatureVecs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print ('Building tf-idf matrix ...')\n",
    "vectorizer = TfidfVectorizer(analyzer=lambda x: x, min_df=10)\n",
    "matrix = vectorizer.fit_transform([x for x in X_train])\n",
    "tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "print ('vocab size : {}'.format(len(tfidf)))\n",
    "\n",
    "def buildWordVector(model, tfidf, tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model[word].reshape((1, size)) * tfidf[word]\n",
    "            count += 1.\n",
    "        except KeyError: \n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f_train = np.concatenate([buildWordVector(model, tfidf, z, num_features) for z in tqdm(map(lambda x: x, X_train))])\n",
    "#f_valid = np.concatenate([buildWordVector(model, tfidf, z, num_features) for z in tqdm(map(lambda x: x, X_valid))])\n",
    "\n",
    "f_train = getAvgFeatureVecs(X_train, W2Vmodel, num_features)\n",
    "f_valid = getAvgFeatureVecs(X_valid, W2Vmodel, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of train features:: {}'.format(f_train.shape))\n",
    "print('Shape of valid features:: {}'.format(f_valid.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalization_type = 'zScore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Normalization type: {}'.format(normalization_type))\n",
    "\n",
    "if normalization_type == 'minMax':\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "elif normalization_type == 'zScore':        \n",
    "    scaler =  StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## data normalization\n",
    "f_train = scaler.fit_transform(f_train)\n",
    "f_valid = scaler.transform(f_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words visualization using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_pca(f_train, y_train, nb_clusters = 5):\n",
    "\n",
    "    palette = np.array(sns.color_palette(\"hls\", nb_clusters))\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    result = pca.fit_transform(f_train)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))     \n",
    "    plt.scatter(result[:, 0], result[:, 1], lw=0, s=40,\n",
    "                    c=palette[y_train.astype(np.int)])\n",
    "\n",
    "    plt.title('Visualization PCA')\n",
    "    plt.axis('off')\n",
    "    plt.axis('tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca(f_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words visualization using t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_tSNE(model,n_samples = 5000):\n",
    "\n",
    "    \n",
    "    #https://www.oreilly.com/learning/an-illustrated-introduction-to-the-t-sne-algorithm\n",
    "\n",
    "    output_notebook()\n",
    "    fig = bp.figure(plot_width=700, plot_height=600, title=\"A map of \" + str(n_samples) + \" word vectors\",\n",
    "        tools=\"pan,wheel_zoom,box_zoom,reset,hover,previewsave\",\n",
    "        x_axis_type=None, y_axis_type=None, min_border=1)\n",
    "\n",
    "\n",
    "    word_vectors = [model[w] for w in model.wv.vocab.keys()][:n_samples]\n",
    "    #word_vectors = [token for token in f_matrix_train][0:n_samples]\n",
    "\n",
    "    tsne_model = TSNE(n_components=2, verbose=1, random_state=23)\n",
    "    tsne_w2v = tsne_model.fit_transform(word_vectors)\n",
    "\n",
    "    tsne_df = pd.DataFrame(tsne_w2v, columns=['x', 'y'])\n",
    "    tsne_df['words'] = [k for k in model.wv.vocab.keys()][:n_samples]\n",
    "\n",
    "    fig.scatter(x='x', y='y', source=tsne_df)\n",
    "    hover = fig.select(dict(type=HoverTool))\n",
    "    hover.tooltips={\"word\": \"@words\"}\n",
    "    show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tSNE(W2Vmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining number of clusters - Elbow Rule\n",
    "###### When K increases, the centroids are closer to the clusters centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k means determine k\n",
    "distortions = []\n",
    "max_nb_cluster = 10\n",
    "for k in range(1,max_nb_cluster):\n",
    "    print('Training K-means models for {} cluster/s...'.format(k))\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(f_train)\n",
    "    kmeanModel.fit(f_train)\n",
    "    distortions.append(sum(np.min(cdist(f_train, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / f_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the elbow\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(1,max_nb_cluster), distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 5\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "print('Trainning K-Means...')\n",
    "\n",
    "kmeans.fit(f_train, y_train)\n",
    "\n",
    "score = metrics.accuracy_score(y_valid, kmeans.predict(f_valid))\n",
    "print('K-Means - Accuracy on the valid set: {0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time() # Start time\n",
    "idx = kmeans.predict( f_train )\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print (\"Time taken for K Means clustering: \", elapsed, \"seconds.\")\n",
    "\n",
    "# Create a Word / Index dictionary, mapping each vocabulary word to\n",
    "# a cluster number                                                                                            \n",
    "word_centroid_map = dict(zip( W2Vmodel.wv.index2word, idx ))\n",
    "\n",
    "# For the first 5 clusters\n",
    "for cluster in range(0,num_clusters):\n",
    "    \n",
    "    print (\"\\nCluster %d\" % cluster)\n",
    "    words = []\n",
    "    for key, value in word_centroid_map.items():\n",
    "        if( value == cluster ):\n",
    "            words.append(key)\n",
    "    print (words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 600)               180600    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 3005      \n",
      "=================================================================\n",
      "Total params: 183,605\n",
      "Trainable params: 183,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation \n",
    "from keras.optimizers import SGD\n",
    "\n",
    "output_dim  = nb_classes = num_clusters = 5\n",
    "cmodel = Sequential() \n",
    "\n",
    "cmodel.add(Dense(2*num_features, input_dim=num_features, activation='relu'))\n",
    "cmodel.add(Dense(output_dim, activation='softmax')) \n",
    "cmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils \n",
    "Y_oh_train = np_utils.to_categorical(y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      " - 14s - loss: 1.2555 - acc: 0.5088\n",
      "Epoch 2/9\n",
      " - 16s - loss: 1.2150 - acc: 0.5201\n",
      "Epoch 3/9\n",
      " - 15s - loss: 1.2128 - acc: 0.5227\n",
      "Epoch 4/9\n",
      " - 18s - loss: 1.2156 - acc: 0.5243\n",
      "Epoch 5/9\n",
      " - 14s - loss: 1.2202 - acc: 0.5253\n",
      "Epoch 6/9\n",
      " - 16s - loss: 1.2287 - acc: 0.5245\n",
      "Epoch 7/9\n",
      " - 16s - loss: 1.2336 - acc: 0.5247\n",
      "Epoch 8/9\n",
      " - 15s - loss: 1.2333 - acc: 0.5261\n",
      "Epoch 9/9\n",
      " - 14s - loss: 1.2432 - acc: 0.5248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x134112fd0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmodel.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "cmodel.fit(f_train, Y_oh_train, epochs=9, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_acuracy(model, Xc, Y):\n",
    "    Y_hat = model.predict_classes(Xc)\n",
    "    accuracy = sum(Y_hat == Y)/(float(len(Y)))\n",
    "    print('Accuracy: {}'.format(accuracy) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.516243752402922\n",
      "Accuracy: 0.5253428168653083\n"
     ]
    }
   ],
   "source": [
    "get_acuracy(cmodel, f_valid, y_valid)\n",
    "get_acuracy(cmodel, f_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = cmodel.predict_classes(f_train)\n",
    "df_confusion = pd.crosstab(Y_hat, y_train, rownames=['Atual'], colnames=['Predicted'], normalize='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARUAAADuCAYAAAAXzJOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSioiEpWSiohEpaQiIlEpqYhIVP8Hh5uLF3IK4skAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x137c3bb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_confusion_matrix(df_confusion, title='Confusion matrix', cmap=plt.cm.gray_r):\n",
    "    plt.matshow(df_confusion, cmap=cmap) # imshow\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(df_confusion.columns))\n",
    "    plt.xticks(tick_marks, df_confusion.columns, rotation=45)\n",
    "    plt.yticks(tick_marks, df_confusion.index)\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel(df_confusion.index.name)\n",
    "    plt.xlabel(df_confusion.columns.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(df_confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
