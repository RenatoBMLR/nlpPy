{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('../src/'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.plotting_context('paper')\n",
    "\n",
    "from wordGraph import *\n",
    "from textDataset import *\n",
    "from trainner import TrainnerNLP\n",
    "\n",
    "from torchvision import transforms\n",
    "import networkx as nx\n",
    "\n",
    "from models import BoWClassifier, Tfid\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path2data = '../data/toxic/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = {\n",
    "    'train': TextProcessing(path2data + 'train/', is_train = True),\n",
    "    'train': TextProcessing(path2data + 'train/', is_valid = True),\n",
    "    'test':  TextProcessing(path2data + 'test/',  is_test=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['train'].data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['train'].process_data(col = 'comment_text', lemmalize = False, stem = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['train'].data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['test'].data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = 'comment_text_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# index into the Bag of words vector\n",
    "words_ix = {}\n",
    "words_voc = []\n",
    "for index, row in text['train'].data[col].iteritems():\n",
    "    for word in row.split():\n",
    "        words_voc.append(word)\n",
    "        if word not in words_ix:\n",
    "            words_ix[word] = len(words_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(words_ix)\n",
    "NUM_LABELS = 6\n",
    "print('VOCAB_SIZE: {} NUM_LABELS: {}'.format(VOCAB_SIZE, NUM_LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.MultiLabelMarginLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'model' : model, \n",
    "    'criterion': loss_fn,  \n",
    "    'optimizer': optimizer, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = text['train'].data[['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "   'insult', 'identity_hate']].values\n",
    "\n",
    "x_train = np.vstack( text['train'].make_bow_vector('comment_text_data', words_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['test'].process_data(col = 'comment_text', lemmalize = False, stem = False)\n",
    "x_test = np.vstack( text['test'].make_bow_vector('comment_text_data', words_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsets = {\n",
    "            'train': TextDataset(x_train, y_train),\n",
    "            'test': TextDataset(x_train, is_test = True)\n",
    "}\n",
    "    \n",
    "dset_loaders = create_dataLoader(dsets, 10, pin_memory=False, use_shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NLPtrainner = TrainnerNLP(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLPtrainner.train(dset_loaders['train'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
